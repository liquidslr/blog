{"componentChunkName":"component---src-templates-blog-post-js","path":"/reinforcement-learning/","result":{"data":{"site":{"siteMetadata":{"title":"Personal Blog"}},"markdownRemark":{"id":"f45a472b-a172-579c-8970-6f4c9f717c56","excerpt":"Introduction to Reinforcement Learning Reinforcement Learning (RL) is an area of machine learning concerned with how agents ought to take actions in an…","html":"<h2>Introduction to Reinforcement Learning</h2>\n<p>Reinforcement Learning (RL) is an area of machine learning concerned with how agents ought to take actions in an environment to maximize some notion of cumulative reward. In RL, an agent interacts with the environment in a loop:</p>\n<ol>\n<li><strong>Observation</strong>: The agent observes the current state of the environment.</li>\n<li><strong>Action</strong>: Based on the observation, the agent chooses an action.</li>\n<li><strong>Reward</strong>: The environment transitions to a new state, and the agent receives a reward associated with the transition.</li>\n</ol>\n<p>The goal of the agent is to learn a policy <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cpi\" alt=\"Policy\"> that maximizes the expected cumulative reward, often called the return <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;G_t=R_%7Bt+1%7D+%5Cgamma&#x26;space;R_%7Bt+2%7D+%5Cgamma%5E2&#x26;space;R_%7Bt+3%7D+%5Cldots\" alt=\"Return\">.</p>\n<p>Here, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;R_%7Bt+1%7D\" alt=\"Reward\"> is the reward received after taking action <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;a_t\" alt=\"Action\"> in state <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;s_t\" alt=\"State\">, and <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cgamma\" alt=\"Gamma\"> (0 ≤ <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cgamma\" alt=\"Gamma\"> &#x3C; 1) is the discount factor, which models the agent's consideration of future rewards.</p>\n<h2>Key Concepts in Reinforcement Learning</h2>\n<ul>\n<li><strong>State (s)</strong>: A representation of the current situation in the environment.</li>\n<li><strong>Action (a)</strong>: A decision or move made by the agent.</li>\n<li><strong>Policy (<img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cpi\" alt=\"Policy\">)</strong>: A mapping from states to probabilities of selecting each possible action.</li>\n<li><strong>Reward (r)</strong>: Feedback from the environment used to evaluate the action taken.</li>\n<li><strong>Value Function (<img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;V(s)\" alt=\"Value Function\">)</strong>: The expected return starting from state <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;s\" alt=\"State\"> and following the policy <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cpi\" alt=\"Policy\">.</li>\n<li><strong>Q-Function (<img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;Q(s,%20a)\" alt=\"Q-Function\">)</strong>: The expected return starting from state <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;s\" alt=\"State\">, taking action <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;a\" alt=\"Action\">, and thereafter following policy <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cpi\" alt=\"Policy\">.</li>\n</ul>\n<h2>Types of RL Algorithms</h2>\n<h3>Q-Learning</h3>\n<p>Q-Learning is a model-free, off-policy RL algorithm. It estimates the value of taking an action <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;a\" alt=\"Action\"> in a state <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;s\" alt=\"State\"> and follows the Bellman equation for updating the Q-values:</p>\n<p><img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;Q(s,%20a)%20%5Cleftarrow%20Q(s,%20a)%20+%20%5Calpha%20%5Cleft%5B%20r%20+%20%5Cgamma%20%5Cmax_%7Ba&#x27;%7D%20Q(s&#x27;,%20a&#x27;)%20-%20Q(s,%20a)%20%5Cright%5D\" alt=\"Q-Learning Equation\"></p>\n<p>Here, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Calpha\" alt=\"Alpha\"> is the learning rate, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r\" alt=\"Reward\"> is the immediate reward, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;s&#x27;\" alt=\"Next State\"> is the next state, and <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cgamma\" alt=\"Gamma\"> is the discount factor.</p>\n<h3>Deep Q-Networks (DQN)</h3>\n<p>DQN extends Q-learning by using a deep neural network to approximate the Q-function. The neural network takes the state as input and outputs Q-values for all possible actions.</p>\n<p>Key innovations in DQN include:</p>\n<ul>\n<li><strong>Experience Replay</strong>: Storing past experiences and sampling them randomly during training to break correlations between consecutive experiences.</li>\n<li><strong>Target Network</strong>: A separate network for estimating the target Q-value, which is periodically updated with the weights of the main network to stabilize training.</li>\n</ul>\n<h3>Policy Gradient Methods</h3>\n<p>Policy gradient methods directly optimize the policy by computing the gradient of the expected reward concerning the policy parameters <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Ctheta\" alt=\"Theta\">:</p>\n<p><img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cnabla_%7B%5Ctheta%7D%20J(%5Ctheta)%20=%20%5Cmathbb%7BE%7D_%7B%5Cpi_%7B%5Ctheta%7D%7D%20%5Cleft%5B%20%5Cnabla_%7B%5Ctheta%7D%20%5Clog%20%5Cpi_%7B%5Ctheta%7D(a%20%7C%20s)%20Q%5E%7B%5Cpi_%7B%5Ctheta%7D%7D(s,%20a)%20%5Cright%5D\" alt=\"Policy Gradient Equation\"></p>\n<p>The policy <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cpi_%7B%5Ctheta%7D\" alt=\"Policy Theta\"> is often parameterized by a neural network, and the gradient ascent method is used to improve the policy.</p>\n<h3>Proximal Policy Optimization (PPO)</h3>\n<p>PPO is an advanced policy gradient method that introduces a clipped objective to prevent the policy from updating too far in a single step, balancing exploration and exploitation. The PPO objective function is given by:</p>\n<p><img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;L%5E%7BCLIP%7D(%5Ctheta)%20=%20%5Cmathbb%7BE%7D_t%20%5Cleft%5B%20%5Cmin%20%5Cleft(%20r_t(%5Ctheta)%20%5Chat%7BA%7D_t,%20%5Ctext%7Bclip%7D(r_t(%5Ctheta),%201%20-%20%5Cepsilon,%201%20+%20%5Cepsilon)%20%5Chat%7BA%7D_t%20%5Cright)%20%5Cright%5D\" alt=\"PPO Objective\"></p>\n<p>Where <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r_t(%5Ctheta)\" alt=\"r_t(theta)\"> is the ratio of the new policy to the old policy, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Chat%7BA%7D_t\" alt=\"Advantage\"> is the advantage function, and <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cepsilon\" alt=\"Epsilon\"> is a small hyperparameter that controls the clipping range.</p>\n<h2>The Flappy Bird Game</h2>\n<p><img src=\"https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExcnFiODkwbzN1aDFmdG85aGk0a3RlMTFidGpmN2t4azNoODJqM2M0dyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/kKj5Olw5JobOhiFVHs/giphy.gif\" alt=\"Flappy Bird Gameplay\"></p>\n<p>Flappy Bird is a side-scrolling game where the player controls a bird attempting to fly between sets of pipes without colliding with them. The game is deceptively simple but highly challenging, making it an ideal candidate for applying RL.</p>\n<h2>Game Details</h2>\n<ul>\n<li><strong>State Space</strong>: The state of the game can be represented by features such as the bird's vertical position, its velocity, the distance to the next pipe, and the position of the gap in the next pipe.</li>\n<li><strong>Action Space</strong>: The action space is discrete, with two possible actions: flap (which makes the bird ascend) or do nothing (which causes the bird to descend).</li>\n<li><strong>Reward System</strong>: Designing an appropriate reward system is crucial. Possible rewards include:\n<ul>\n<li>A positive reward for successfully passing through a gap.</li>\n<li>A negative reward for colliding with a pipe or the ground.</li>\n<li>A small negative reward for each timestep to encourage the bird to move forward rather than hover in place.</li>\n</ul>\n</li>\n</ul>\n<h2>Mathematical Formulation</h2>\n<p>In the context of Flappy Bird, we define the reward function <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r(s,%20a)\" alt=\"Reward Function\"> based on the outcomes of each action:</p>\n<ul>\n<li>If the bird passes through a pipe, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r(s,%20a)%20=%20+1\" alt=\"Positive Reward\">.</li>\n<li>If the bird hits a pipe or the ground, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r(s,%20a)%20=%20-1\" alt=\"Negative Reward\">.</li>\n<li>For each frame survived, a small negative reward can be given to encourage the bird to make progress, for example, <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;r(s,%20a)%20=%20-0.01\" alt=\"Timestep Reward\">.</li>\n</ul>\n<p>The Q-values can be updated using the Q-learning rule:</p>\n<p><img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;Q(s_t,%20a_t)%20%5Cleftarrow%20Q(s_t,%20a_t)%20+%20%5Calpha%20%5Cleft%5B%20r_%7Bt+1%7D%20+%20%5Cgamma%20%5Cmax_%7Ba&#x27;%7D%20Q(s_%7Bt+1%7D,%20a&#x27;)%20-%20Q(s_t,%20a_t)%20%5Cright%5D\" alt=\"Q-Learning Update\"></p>\n<h2>Implementation Details</h2>\n<p>To implement the Flappy Bird environment and train an RL agent, we'll leverage OpenAI Gym, a toolkit that provides the standard API for interfacing with various environments.</p>\n<h3>Custom Environment</h3>\n<p>The custom Flappy Bird environment is implemented in the <code class=\"language-text\">flappyenv.py</code> file. It inherits from the <code class=\"language-text\">gym.Env</code> class and implements the necessary methods (<code class=\"language-text\">reset()</code>, <code class=\"language-text\">step()</code>, etc.) to interact with the agent.</p>\n<h4>Key Components</h4>\n<p>Below are the key components of the Flappy Bird game implemented using Pygame:</p>\n<ol>\n<li>\n<p><strong>Bird Class</strong>: Represents the bird controlled by the agent.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Bird class</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Bird</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> <span class=\"token number\">50</span>\n        self<span class=\"token punctuation\">.</span>y <span class=\"token operator\">=</span> SCREEN_HEIGHT <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n        self<span class=\"token punctuation\">.</span>velocity <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">draw</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        screen<span class=\"token punctuation\">.</span>blit<span class=\"token punctuation\">(</span>bird_image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>velocity <span class=\"token operator\">+=</span> GRAVITY\n        self<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+=</span> self<span class=\"token punctuation\">.</span>velocity\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">jump</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>velocity <span class=\"token operator\">=</span> JUMP_STRENGTH\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">fall_faster</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>velocity <span class=\"token operator\">+=</span> FALL_STRENGTH\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_rect</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> pygame<span class=\"token punctuation\">.</span>Rect<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">,</span> BIRD_WIDTH<span class=\"token punctuation\">,</span> BIRD_HEIGHT<span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>Explanation:</strong></p>\n<ul>\n<li><strong>Initialization</strong>: Sets the bird's starting position and initial velocity.</li>\n<li><strong>Draw Method</strong>: Renders the bird image on the screen.</li>\n<li><strong>Update Method</strong>: Applies gravity to the bird, updating its vertical position.</li>\n<li><strong>Jump Method</strong>: Makes the bird ascend by setting a negative velocity.</li>\n<li><strong>Fall Faster Method</strong>: Increases the bird's velocity to make it descend more quickly.</li>\n<li><strong>Get Rect Method</strong>: Returns the bird's rectangle for collision detection.</li>\n</ul>\n</li>\n<li>\n<p><strong>Pipe Class</strong>: Represents the obstacles the bird must navigate through.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Pipe class</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Pipe</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> SCREEN_WIDTH\n        self<span class=\"token punctuation\">.</span>height <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">400</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>top_rect <span class=\"token operator\">=</span> pygame<span class=\"token punctuation\">.</span>Rect<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> PIPE_WIDTH<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>height<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bottom_rect <span class=\"token operator\">=</span> pygame<span class=\"token punctuation\">.</span>Rect<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>height <span class=\"token operator\">+</span> PIPE_GAP<span class=\"token punctuation\">,</span> PIPE_WIDTH<span class=\"token punctuation\">,</span> SCREEN_HEIGHT<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">draw</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        pygame<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">.</span>rect<span class=\"token punctuation\">(</span>screen<span class=\"token punctuation\">,</span> GREEN<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>top_rect<span class=\"token punctuation\">)</span>\n        pygame<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">.</span>rect<span class=\"token punctuation\">(</span>screen<span class=\"token punctuation\">,</span> GREEN<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>bottom_rect<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>x <span class=\"token operator\">-=</span> PIPE_SPEED\n        self<span class=\"token punctuation\">.</span>top_rect<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>x\n        self<span class=\"token punctuation\">.</span>bottom_rect<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>x</code></pre></div>\n<p><strong>Explanation:</strong></p>\n<ul>\n<li><strong>Initialization</strong>: Sets the pipe's starting position and randomly determines the height of the top pipe.</li>\n<li><strong>Draw Method</strong>: Renders the top and bottom pipes on the screen.</li>\n<li><strong>Update Method</strong>: Moves the pipes to the left, simulating the bird's forward movement.</li>\n</ul>\n</li>\n<li>\n<p><strong>Main Game Loop</strong>: Handles game events, updates game objects, and renders the game.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Main game loop</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    clock <span class=\"token operator\">=</span> pygame<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">.</span>Clock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    bird <span class=\"token operator\">=</span> Bird<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    pipes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Pipe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    score <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    running <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n\n    <span class=\"token keyword\">while</span> running<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> event <span class=\"token keyword\">in</span> pygame<span class=\"token punctuation\">.</span>event<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> event<span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span> <span class=\"token operator\">==</span> pygame<span class=\"token punctuation\">.</span>QUIT<span class=\"token punctuation\">:</span>\n                pygame<span class=\"token punctuation\">.</span>quit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> event<span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span> <span class=\"token operator\">==</span> pygame<span class=\"token punctuation\">.</span>KEYDOWN<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> event<span class=\"token punctuation\">.</span>key <span class=\"token operator\">==</span> pygame<span class=\"token punctuation\">.</span>K_SPACE <span class=\"token keyword\">or</span> event<span class=\"token punctuation\">.</span>key <span class=\"token operator\">==</span> pygame<span class=\"token punctuation\">.</span>K_UP<span class=\"token punctuation\">:</span>\n                    bird<span class=\"token punctuation\">.</span>jump<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">if</span> event<span class=\"token punctuation\">.</span>key <span class=\"token operator\">==</span> pygame<span class=\"token punctuation\">.</span>K_DOWN<span class=\"token punctuation\">:</span>\n                    bird<span class=\"token punctuation\">.</span>fall_faster<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Update game objects</span>\n        bird<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> pipe <span class=\"token keyword\">in</span> pipes<span class=\"token punctuation\">:</span>\n            pipe<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Check for collisions</span>\n        bird_rect <span class=\"token operator\">=</span> bird<span class=\"token punctuation\">.</span>get_rect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> bird<span class=\"token punctuation\">.</span>y <span class=\"token operator\">&lt;</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> bird<span class=\"token punctuation\">.</span>y <span class=\"token operator\">></span> SCREEN_HEIGHT<span class=\"token punctuation\">:</span>\n            running <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n        <span class=\"token keyword\">for</span> pipe <span class=\"token keyword\">in</span> pipes<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> pipe<span class=\"token punctuation\">.</span>top_rect<span class=\"token punctuation\">.</span>colliderect<span class=\"token punctuation\">(</span>bird_rect<span class=\"token punctuation\">)</span> <span class=\"token keyword\">or</span> pipe<span class=\"token punctuation\">.</span>bottom_rect<span class=\"token punctuation\">.</span>colliderect<span class=\"token punctuation\">(</span>bird_rect<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                running <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n\n        <span class=\"token comment\"># Add new pipes</span>\n        <span class=\"token keyword\">if</span> pipes<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>x <span class=\"token operator\">&lt;</span> SCREEN_WIDTH <span class=\"token operator\">-</span> <span class=\"token number\">200</span><span class=\"token punctuation\">:</span>\n            pipes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>Pipe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Remove off-screen pipes</span>\n        <span class=\"token keyword\">if</span> pipes<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>x <span class=\"token operator\">&lt;</span> <span class=\"token operator\">-</span>PIPE_WIDTH<span class=\"token punctuation\">:</span>\n            pipes<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n            score <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\n        <span class=\"token comment\"># Draw everything</span>\n        screen<span class=\"token punctuation\">.</span>blit<span class=\"token punctuation\">(</span>background_image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Draw background</span>\n        bird<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> pipe <span class=\"token keyword\">in</span> pipes<span class=\"token punctuation\">:</span>\n            pipe<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Draw score</span>\n        font <span class=\"token operator\">=</span> pygame<span class=\"token punctuation\">.</span>font<span class=\"token punctuation\">.</span>Font<span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token number\">36</span><span class=\"token punctuation\">)</span>\n        score_text <span class=\"token operator\">=</span> font<span class=\"token punctuation\">.</span>render<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Score: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>score<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> BLACK<span class=\"token punctuation\">)</span>\n        screen<span class=\"token punctuation\">.</span>blit<span class=\"token punctuation\">(</span>score_text<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        pygame<span class=\"token punctuation\">.</span>display<span class=\"token punctuation\">.</span>flip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        clock<span class=\"token punctuation\">.</span>tick<span class=\"token punctuation\">(</span>FPS<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>Explanation:</strong></p>\n<ul>\n<li><strong>Event Handling</strong>: Listens for user inputs to control the bird's actions.</li>\n<li><strong>Updating Objects</strong>: Updates the bird's position and moves the pipes.</li>\n<li><strong>Collision Detection</strong>: Checks if the bird has collided with pipes or gone out of bounds.</li>\n<li><strong>Pipe Management</strong>: Adds new pipes and removes pipes that have moved off-screen, updating the score accordingly.</li>\n<li><strong>Rendering</strong>: Draws the background, bird, pipes, and score on the screen.</li>\n<li><strong>Game Loop Control</strong>: Ensures the game runs at the specified frames per second (FPS) and handles quitting the game.</li>\n</ul>\n</li>\n</ol>\n<h3>Agent Training</h3>\n<p>Training involves running episodes where the agent interacts with the environment, collecting experiences, and updating its policy or Q-values based on the observed rewards. Over time, the agent learns to avoid obstacles and navigate through the pipes more effectively.\nDepending on the algorithm, we will define the neural network architecture, loss functions, and training loop.</p>\n<h4>Example: Q-Learning Update in Code</h4>\n<p>Here's how the Q-learning update rule is implemented in the code:</p>\n<p><img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;Q(s_t,%20a_t)%20%5Cleftarrow%20Q(s_t,%20a_t)%20+%20%5Calpha%20%5Cleft%5B%20r_%7Bt+1%7D%20+%20%5Cgamma%20%5Cmax_%7Ba&#x27;%7D%20Q(s_%7Bt+1%7D,%20a&#x27;)%20-%20Q(s_t,%20a_t)%20%5Cright%5D\" alt=\"Q-Learning Update\"></p>\n<p><strong>Explanation:</strong></p>\n<ul>\n<li><strong>Q-Value Update</strong>: Adjusts the Q-value for the current state-action pair based on the received reward and the maximum expected future rewards.</li>\n<li><strong>Learning Rate (<img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Calpha\" alt=\"Alpha\">)</strong>: Determines how much new information overrides old information.</li>\n<li><strong>Discount Factor (<img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cgamma\" alt=\"Gamma\">)</strong>: Balances immediate and future rewards.</li>\n</ul>\n<h3>Challenges and Solutions</h3>\n<ul>\n<li><strong>Exploration vs. Exploitation</strong>: Balancing exploration (trying new actions) and exploitation (choosing the best-known action) is crucial. Techniques like <img src=\"https://latex.codecogs.com/png.image?%5Cinline&#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&#x26;space;%5Cepsilon-greedy\" alt=\"Epsilon-Greedy\"> in Q-learning or entropy regularization in PPO can help.</li>\n<li><strong>Stabilizing Training</strong>: In DQN, techniques like experience replay and target networks help stabilize the training process, preventing the network from diverging.</li>\n</ul>\n<h2>Summary</h2>\n<p>Reinforcement Learning offers a robust framework for training agents to perform tasks like playing games autonomously. By applying RL to the Flappy Bird game, we explored key concepts such as Q-learning, DQN, and PPO, and discussed the importance of reward system design in guiding the agent's learning process.</p>\n<p>With the help of OpenAI Gym, implementing and experimenting with RL algorithms becomes more accessible, allowing us to train an agent to successfully navigate the challenging environment of Flappy Bird. The journey of training an RL agent involves balancing exploration and exploitation, stabilizing training, and fine-tuning rewards.</p>","frontmatter":{"title":"Flappy Bird Game Using Reinforcement Learning","date":"March 13, 2024","description":null}},"previous":{"fields":{"slug":"/big-data-hackathon/"},"frontmatter":{"title":"My first Big Data hackathon!"}},"next":null},"pageContext":{"id":"f45a472b-a172-579c-8970-6f4c9f717c56","previousPostId":"70fd7550-4da2-563c-8d6f-f43ba19df8e9","nextPostId":null}},"staticQueryHashes":["2841359383","3257411868"],"slicesMap":{}}