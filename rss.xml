<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Personal Blog RSS Feed]]></title><description><![CDATA[A starter blog demonstrating what Gatsby can do.]]></description><link>https://gatsbystarterblogsource.gatsbyjs.io</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 13 Nov 2024 23:48:16 GMT</lastBuildDate><item><title><![CDATA[Flappy Bird Game Using Reinforcement Learning]]></title><description><![CDATA[Introduction to Reinforcement Learning Reinforcement Learning (RL) is an area of machine learning concerned with how agents ought to take…]]></description><link>https://gatsbystarterblogsource.gatsbyjs.io/reinforcement-learning/</link><guid isPermaLink="false">https://gatsbystarterblogsource.gatsbyjs.io/reinforcement-learning/</guid><pubDate>Wed, 13 Mar 2024 23:46:37 GMT</pubDate><content:encoded>&lt;h2&gt;Introduction to Reinforcement Learning&lt;/h2&gt;
&lt;p&gt;Reinforcement Learning (RL) is an area of machine learning concerned with how agents ought to take actions in an environment to maximize some notion of cumulative reward. In RL, an agent interacts with the environment in a loop:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Observation&lt;/strong&gt;: The agent observes the current state of the environment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: Based on the observation, the agent chooses an action.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reward&lt;/strong&gt;: The environment transitions to a new state, and the agent receives a reward associated with the transition.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The goal of the agent is to learn a policy &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cpi&quot; alt=&quot;Policy&quot;&gt; that maximizes the expected cumulative reward, often called the return &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;G_t=R_%7Bt+1%7D+%5Cgamma&amp;#x26;space;R_%7Bt+2%7D+%5Cgamma%5E2&amp;#x26;space;R_%7Bt+3%7D+%5Cldots&quot; alt=&quot;Return&quot;&gt;.&lt;/p&gt;
&lt;p&gt;Here, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;R_%7Bt+1%7D&quot; alt=&quot;Reward&quot;&gt; is the reward received after taking action &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;a_t&quot; alt=&quot;Action&quot;&gt; in state &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;s_t&quot; alt=&quot;State&quot;&gt;, and &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cgamma&quot; alt=&quot;Gamma&quot;&gt; (0 ≤ &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cgamma&quot; alt=&quot;Gamma&quot;&gt; &amp;#x3C; 1) is the discount factor, which models the agent&apos;s consideration of future rewards.&lt;/p&gt;
&lt;h2&gt;Key Concepts in Reinforcement Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;State (s)&lt;/strong&gt;: A representation of the current situation in the environment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action (a)&lt;/strong&gt;: A decision or move made by the agent.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Policy (&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cpi&quot; alt=&quot;Policy&quot;&gt;)&lt;/strong&gt;: A mapping from states to probabilities of selecting each possible action.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reward (r)&lt;/strong&gt;: Feedback from the environment used to evaluate the action taken.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value Function (&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;V(s)&quot; alt=&quot;Value Function&quot;&gt;)&lt;/strong&gt;: The expected return starting from state &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;s&quot; alt=&quot;State&quot;&gt; and following the policy &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cpi&quot; alt=&quot;Policy&quot;&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Q-Function (&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;Q(s,%20a)&quot; alt=&quot;Q-Function&quot;&gt;)&lt;/strong&gt;: The expected return starting from state &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;s&quot; alt=&quot;State&quot;&gt;, taking action &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;a&quot; alt=&quot;Action&quot;&gt;, and thereafter following policy &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cpi&quot; alt=&quot;Policy&quot;&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Types of RL Algorithms&lt;/h2&gt;
&lt;h3&gt;Q-Learning&lt;/h3&gt;
&lt;p&gt;Q-Learning is a model-free, off-policy RL algorithm. It estimates the value of taking an action &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;a&quot; alt=&quot;Action&quot;&gt; in a state &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;s&quot; alt=&quot;State&quot;&gt; and follows the Bellman equation for updating the Q-values:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;Q(s,%20a)%20%5Cleftarrow%20Q(s,%20a)%20+%20%5Calpha%20%5Cleft%5B%20r%20+%20%5Cgamma%20%5Cmax_%7Ba&amp;#x27;%7D%20Q(s&amp;#x27;,%20a&amp;#x27;)%20-%20Q(s,%20a)%20%5Cright%5D&quot; alt=&quot;Q-Learning Equation&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Calpha&quot; alt=&quot;Alpha&quot;&gt; is the learning rate, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r&quot; alt=&quot;Reward&quot;&gt; is the immediate reward, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;s&amp;#x27;&quot; alt=&quot;Next State&quot;&gt; is the next state, and &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cgamma&quot; alt=&quot;Gamma&quot;&gt; is the discount factor.&lt;/p&gt;
&lt;h3&gt;Deep Q-Networks (DQN)&lt;/h3&gt;
&lt;p&gt;DQN extends Q-learning by using a deep neural network to approximate the Q-function. The neural network takes the state as input and outputs Q-values for all possible actions.&lt;/p&gt;
&lt;p&gt;Key innovations in DQN include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Experience Replay&lt;/strong&gt;: Storing past experiences and sampling them randomly during training to break correlations between consecutive experiences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Target Network&lt;/strong&gt;: A separate network for estimating the target Q-value, which is periodically updated with the weights of the main network to stabilize training.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Policy Gradient Methods&lt;/h3&gt;
&lt;p&gt;Policy gradient methods directly optimize the policy by computing the gradient of the expected reward concerning the policy parameters &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Ctheta&quot; alt=&quot;Theta&quot;&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cnabla_%7B%5Ctheta%7D%20J(%5Ctheta)%20=%20%5Cmathbb%7BE%7D_%7B%5Cpi_%7B%5Ctheta%7D%7D%20%5Cleft%5B%20%5Cnabla_%7B%5Ctheta%7D%20%5Clog%20%5Cpi_%7B%5Ctheta%7D(a%20%7C%20s)%20Q%5E%7B%5Cpi_%7B%5Ctheta%7D%7D(s,%20a)%20%5Cright%5D&quot; alt=&quot;Policy Gradient Equation&quot;&gt;&lt;/p&gt;
&lt;p&gt;The policy &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cpi_%7B%5Ctheta%7D&quot; alt=&quot;Policy Theta&quot;&gt; is often parameterized by a neural network, and the gradient ascent method is used to improve the policy.&lt;/p&gt;
&lt;h3&gt;Proximal Policy Optimization (PPO)&lt;/h3&gt;
&lt;p&gt;PPO is an advanced policy gradient method that introduces a clipped objective to prevent the policy from updating too far in a single step, balancing exploration and exploitation. The PPO objective function is given by:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;L%5E%7BCLIP%7D(%5Ctheta)%20=%20%5Cmathbb%7BE%7D_t%20%5Cleft%5B%20%5Cmin%20%5Cleft(%20r_t(%5Ctheta)%20%5Chat%7BA%7D_t,%20%5Ctext%7Bclip%7D(r_t(%5Ctheta),%201%20-%20%5Cepsilon,%201%20+%20%5Cepsilon)%20%5Chat%7BA%7D_t%20%5Cright)%20%5Cright%5D&quot; alt=&quot;PPO Objective&quot;&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r_t(%5Ctheta)&quot; alt=&quot;r_t(theta)&quot;&gt; is the ratio of the new policy to the old policy, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Chat%7BA%7D_t&quot; alt=&quot;Advantage&quot;&gt; is the advantage function, and &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cepsilon&quot; alt=&quot;Epsilon&quot;&gt; is a small hyperparameter that controls the clipping range.&lt;/p&gt;
&lt;h2&gt;The Flappy Bird Game&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExcnFiODkwbzN1aDFmdG85aGk0a3RlMTFidGpmN2t4azNoODJqM2M0dyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/kKj5Olw5JobOhiFVHs/giphy.gif&quot; alt=&quot;Flappy Bird Gameplay&quot;&gt;&lt;/p&gt;
&lt;p&gt;Flappy Bird is a side-scrolling game where the player controls a bird attempting to fly between sets of pipes without colliding with them. The game is deceptively simple but highly challenging, making it an ideal candidate for applying RL.&lt;/p&gt;
&lt;h2&gt;Game Details&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;State Space&lt;/strong&gt;: The state of the game can be represented by features such as the bird&apos;s vertical position, its velocity, the distance to the next pipe, and the position of the gap in the next pipe.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action Space&lt;/strong&gt;: The action space is discrete, with two possible actions: flap (which makes the bird ascend) or do nothing (which causes the bird to descend).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reward System&lt;/strong&gt;: Designing an appropriate reward system is crucial. Possible rewards include:
&lt;ul&gt;
&lt;li&gt;A positive reward for successfully passing through a gap.&lt;/li&gt;
&lt;li&gt;A negative reward for colliding with a pipe or the ground.&lt;/li&gt;
&lt;li&gt;A small negative reward for each timestep to encourage the bird to move forward rather than hover in place.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Mathematical Formulation&lt;/h2&gt;
&lt;p&gt;In the context of Flappy Bird, we define the reward function &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r(s,%20a)&quot; alt=&quot;Reward Function&quot;&gt; based on the outcomes of each action:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the bird passes through a pipe, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r(s,%20a)%20=%20+1&quot; alt=&quot;Positive Reward&quot;&gt;.&lt;/li&gt;
&lt;li&gt;If the bird hits a pipe or the ground, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r(s,%20a)%20=%20-1&quot; alt=&quot;Negative Reward&quot;&gt;.&lt;/li&gt;
&lt;li&gt;For each frame survived, a small negative reward can be given to encourage the bird to make progress, for example, &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;r(s,%20a)%20=%20-0.01&quot; alt=&quot;Timestep Reward&quot;&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Q-values can be updated using the Q-learning rule:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;Q(s_t,%20a_t)%20%5Cleftarrow%20Q(s_t,%20a_t)%20+%20%5Calpha%20%5Cleft%5B%20r_%7Bt+1%7D%20+%20%5Cgamma%20%5Cmax_%7Ba&amp;#x27;%7D%20Q(s_%7Bt+1%7D,%20a&amp;#x27;)%20-%20Q(s_t,%20a_t)%20%5Cright%5D&quot; alt=&quot;Q-Learning Update&quot;&gt;&lt;/p&gt;
&lt;h2&gt;Implementation Details&lt;/h2&gt;
&lt;p&gt;To implement the Flappy Bird environment and train an RL agent, we&apos;ll leverage OpenAI Gym, a toolkit that provides the standard API for interfacing with various environments.&lt;/p&gt;
&lt;h3&gt;Custom Environment&lt;/h3&gt;
&lt;p&gt;The custom Flappy Bird environment is implemented in the &lt;code class=&quot;language-text&quot;&gt;flappyenv.py&lt;/code&gt; file. It inherits from the &lt;code class=&quot;language-text&quot;&gt;gym.Env&lt;/code&gt; class and implements the necessary methods (&lt;code class=&quot;language-text&quot;&gt;reset()&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;step()&lt;/code&gt;, etc.) to interact with the agent.&lt;/p&gt;
&lt;h4&gt;Key Components&lt;/h4&gt;
&lt;p&gt;Below are the key components of the Flappy Bird game implemented using Pygame:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bird Class&lt;/strong&gt;: Represents the bird controlled by the agent.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Bird class&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Bird&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;50&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; SCREEN_HEIGHT &lt;span class=&quot;token operator&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;velocity &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        screen&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;blit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bird_image&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;velocity &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; GRAVITY
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;velocity

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;jump&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;velocity &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; JUMP_STRENGTH

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;fall_faster&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;velocity &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; FALL_STRENGTH

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;get_rect&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; BIRD_WIDTH&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; BIRD_HEIGHT&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt;: Sets the bird&apos;s starting position and initial velocity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draw Method&lt;/strong&gt;: Renders the bird image on the screen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update Method&lt;/strong&gt;: Applies gravity to the bird, updating its vertical position.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jump Method&lt;/strong&gt;: Makes the bird ascend by setting a negative velocity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fall Faster Method&lt;/strong&gt;: Increases the bird&apos;s velocity to make it descend more quickly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Get Rect Method&lt;/strong&gt;: Returns the bird&apos;s rectangle for collision detection.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipe Class&lt;/strong&gt;: Represents the obstacles the bird must navigate through.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Pipe class&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Pipe&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; SCREEN_WIDTH
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;height &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; random&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;randint&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;top_rect &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; PIPE_WIDTH&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;height&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;bottom_rect &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;height &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; PIPE_GAP&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; PIPE_WIDTH&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; SCREEN_HEIGHT&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;draw&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;screen&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; GREEN&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;top_rect&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;draw&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;screen&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; GREEN&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;bottom_rect&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;-=&lt;/span&gt; PIPE_SPEED
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;top_rect&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;bottom_rect&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt;: Sets the pipe&apos;s starting position and randomly determines the height of the top pipe.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draw Method&lt;/strong&gt;: Renders the top and bottom pipes on the screen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update Method&lt;/strong&gt;: Moves the pipes to the left, simulating the bird&apos;s forward movement.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Main Game Loop&lt;/strong&gt;: Handles game events, updates game objects, and renders the game.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Main game loop&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    clock &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Clock&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    bird &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Bird&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    pipes &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;Pipe&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
    score &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;
    running &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; running&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; event &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;QUIT&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
                pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;quit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
                sys&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;exit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;KEYDOWN&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;key &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;K_SPACE &lt;span class=&quot;token keyword&quot;&gt;or&lt;/span&gt; event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;key &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;K_UP&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
                    bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;jump&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;key &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;K_DOWN&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
                    bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fall_faster&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token comment&quot;&gt;# Update game objects&lt;/span&gt;
        bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;update&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; pipe &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; pipes&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            pipe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;update&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# Check for collisions&lt;/span&gt;
        bird_rect &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get_rect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;or&lt;/span&gt; bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;y &lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; SCREEN_HEIGHT&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            running &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; pipe &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; pipes&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; pipe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;top_rect&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;colliderect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bird_rect&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;or&lt;/span&gt; pipe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;bottom_rect&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;colliderect&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bird_rect&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
                running &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# Add new pipes&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; pipes&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; SCREEN_WIDTH &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            pipes&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;append&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Pipe&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# Remove off-screen pipes&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; pipes&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;x &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;PIPE_WIDTH&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            pipes&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;pop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
            score &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# Draw everything&lt;/span&gt;
        screen&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;blit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;background_image&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;token comment&quot;&gt;# Draw background&lt;/span&gt;
        bird&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;draw&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; pipe &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; pipes&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            pipe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;draw&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;token comment&quot;&gt;# Draw score&lt;/span&gt;
        font &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;font&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Font&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        score_text &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; font&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;render&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string-interpolation&quot;&gt;&lt;span class=&quot;token string&quot;&gt;f&quot;Score: &lt;/span&gt;&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;score&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; BLACK&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        screen&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;blit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;score_text&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

        pygame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;display&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;flip&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        clock&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tick&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;FPS&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; __name__ &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    main&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Event Handling&lt;/strong&gt;: Listens for user inputs to control the bird&apos;s actions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Updating Objects&lt;/strong&gt;: Updates the bird&apos;s position and moves the pipes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collision Detection&lt;/strong&gt;: Checks if the bird has collided with pipes or gone out of bounds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipe Management&lt;/strong&gt;: Adds new pipes and removes pipes that have moved off-screen, updating the score accordingly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rendering&lt;/strong&gt;: Draws the background, bird, pipes, and score on the screen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Game Loop Control&lt;/strong&gt;: Ensures the game runs at the specified frames per second (FPS) and handles quitting the game.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Agent Training&lt;/h3&gt;
&lt;p&gt;Training involves running episodes where the agent interacts with the environment, collecting experiences, and updating its policy or Q-values based on the observed rewards. Over time, the agent learns to avoid obstacles and navigate through the pipes more effectively.
Depending on the algorithm, we will define the neural network architecture, loss functions, and training loop.
We used PPO algorithm in this case.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; stable_baselines3 &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; PPO
&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; os
&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; stable_baselines3&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;common&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vec_env &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; DummyVecEnv
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; stable_baselines3&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;common&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;env_checker &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; check_env
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; flappyenv &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; FlappyBirdEnv

&lt;span class=&quot;token comment&quot;&gt;# Directories for saving models and logs&lt;/span&gt;
models_dir &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string-interpolation&quot;&gt;&lt;span class=&quot;token string&quot;&gt;f&quot;models/&lt;/span&gt;&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;/&quot;&lt;/span&gt;&lt;/span&gt;
logdir &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string-interpolation&quot;&gt;&lt;span class=&quot;token string&quot;&gt;f&quot;logs/&lt;/span&gt;&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;/&quot;&lt;/span&gt;&lt;/span&gt;

os&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;makedirs&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;models_dir&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; exist_ok&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
os&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;makedirs&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;logdir&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; exist_ok&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Initialize and check the environment&lt;/span&gt;
env &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; FlappyBirdEnv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
check_env&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;env&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; warn&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
env &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; DummyVecEnv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; env&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Initialize the PPO model&lt;/span&gt;
model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; PPO&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;MlpPolicy&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; env&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; verbose&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tensorboard_log&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;logdir&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Training loop&lt;/span&gt;
TIMESTEPS &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1000000&lt;/span&gt;
iters &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    iters &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;
    model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;learn&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_timesteps&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;TIMESTEPS&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; reset_num_timesteps&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tb_log_name&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string-interpolation&quot;&gt;&lt;span class=&quot;token string&quot;&gt;f&quot;PPO&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;save&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string-interpolation&quot;&gt;&lt;span class=&quot;token string&quot;&gt;f&quot;&lt;/span&gt;&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;models_dir&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;TIMESTEPS&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;iters&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;Example: Q-Learning Update in Code&lt;/h4&gt;
&lt;p&gt;Here&apos;s how the Q-learning update rule is implemented in the code:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;Q(s_t,%20a_t)%20%5Cleftarrow%20Q(s_t,%20a_t)%20+%20%5Calpha%20%5Cleft%5B%20r_%7Bt+1%7D%20+%20%5Cgamma%20%5Cmax_%7Ba&amp;#x27;%7D%20Q(s_%7Bt+1%7D,%20a&amp;#x27;)%20-%20Q(s_t,%20a_t)%20%5Cright%5D&quot; alt=&quot;Q-Learning Update&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Q-Value Update&lt;/strong&gt;: Adjusts the Q-value for the current state-action pair based on the received reward and the maximum expected future rewards.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning Rate (&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Calpha&quot; alt=&quot;Alpha&quot;&gt;)&lt;/strong&gt;: Determines how much new information overrides old information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Discount Factor (&lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cgamma&quot; alt=&quot;Gamma&quot;&gt;)&lt;/strong&gt;: Balances immediate and future rewards.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Challenges and Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Exploration vs. Exploitation&lt;/strong&gt;: Balancing exploration (trying new actions) and exploitation (choosing the best-known action) is crucial. Techniques like &lt;img src=&quot;https://latex.codecogs.com/png.image?%5Cinline&amp;#x26;space;%5Cdpi%7B110%7D%5Cbg%7Bwhite%7D&amp;#x26;space;%5Cepsilon-greedy&quot; alt=&quot;Epsilon-Greedy&quot;&gt; in Q-learning or entropy regularization in PPO can help.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stabilizing Training&lt;/strong&gt;: In DQN, techniques like experience replay and target networks help stabilize the training process, preventing the network from diverging.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Reinforcement Learning offers a robust framework for training agents to perform tasks like playing games autonomously. By applying RL to the Flappy Bird game, we explored key concepts such as Q-learning, DQN, and PPO, and discussed the importance of reward system design in guiding the agent&apos;s learning process.&lt;/p&gt;
&lt;p&gt;With the help of OpenAI Gym, implementing and experimenting with RL algorithms becomes more accessible, allowing us to train an agent to successfully navigate the challenging environment of Flappy Bird. The journey of training an RL agent involves balancing exploration and exploitation, stabilizing training, and fine-tuning rewards.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My first Big Data hackathon!]]></title><description><![CDATA[I have always loved participating in hackathons as they give you a chance to apply your knowledge to solve real-world problems. This year, I…]]></description><link>https://gatsbystarterblogsource.gatsbyjs.io/big-data-hackathon/</link><guid isPermaLink="false">https://gatsbystarterblogsource.gatsbyjs.io/big-data-hackathon/</guid><pubDate>Fri, 26 Jan 2024 23:46:37 GMT</pubDate><content:encoded>&lt;p&gt;I have always loved participating in hackathons as they give you a chance to apply your knowledge to solve real-world problems. This year, I got the opportunity to participate in the &lt;a href=&quot;https://bigdata.sc.edu/about/&quot;&gt;5th National Big Data Health Science Student Case Competition&lt;/a&gt;. It&apos;s an annual event organized by USC to promote the use of Big Data analytics in healthcare research (Spoiler Alert: We won!).&lt;/p&gt;
&lt;p&gt;The hackathon spans 48 hours and is divided into two stages. The first stage is a qualifying round for the finals. Around 30 teams from 17 universities, including Duke, Yale, and Boston University, participated. The data came from the lab work of Drs. Ana Pocivavsek and Snezana Milosavljevic. In Round 1, we had to &lt;strong&gt;develop a method to classify unlabeled EEG sleep data from small rodents into three states: paradoxical sleep, slow-wave sleep, or wakefulness.&lt;/strong&gt;.The final round focused on addressing chronic sleep disorders by deploying a machine learning model, emphasizing the reliability and deployment readiness of our first-round model. Our team name was Neural Prognosticators (sounds cool, right?).&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/2bef9/participating_team.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.9620253164557%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADMElEQVR42h1R7W9TdRTuv+IHP4yYGL8YMUQJCZMPqPjywWgI2QcXQogQw2JAR1jUOCIoXZjMEWRAukFZW9ZRabfajW5TbLu2a+/t7b1rx+3Lum5lfdttf7++3PN48SRPnpOTc56c5xxT5JGrLC8stVetj3jcNc/DNiePOB7z0OQ0F1weHrbaeNQ+w+OzT7gw4+LSEy+Pzrh5dNbDIwYHH0zzoOUmkz22dnrJUzIVEpIGXUe70USHcSPVgW4X2y1AYID4EhxIGByo6ojUdXQJRhD+p24Oef8xWr5/FIW5j2umic+O71m+6IN5/0EafbeXCmLiZR9JWxk6Zx+jb5236KPxQRr1O6lr1LfrnG57FRpzSzRsW6MRZ4RWgst6aUdCJrJYNZkPHNJG3nwHl3vewI+v9GB1ygq0OlgML+HVi8fQc+lTmL58HZ/fuoD1Ug7NSg2Lv93D46FreHjmEuau3ERGLVHLMJYR5Jrpxnvva38c/QTGdjC/dRDPnwVADQYxr+LE+E84OfELDl8ewJDjLlrtDupNDndgA44lGXfnRThW1lGuNaht+NqUDMHQ2fPaxnc/QDz7DZKnz8E/cgOiz4dcoQbzdS/Gxp/i+2EXHthCUOQi1M0KBu9H0Xd9Bb1Dc+j//R8oW3V60dSxEU/WTMHeI5r6wYeQ9r8Ncd8+pPv7sTnwNfIhCTZrDPbJVdgmw1jxKQh4BcjKNo5fWcDh8y68dvIhDgw4EUq9oN0mIR0zBJdPfKUlTl9E/NQgYn0D2JqwYts9D0UtwPLsOW77FfzsljD9twSvbwGFQhZC0A7hXwvEgAWq5IHerhJBR14Ua6aYY2ZvazWMnUSS6oUiVXNZYozTnpok9d4wqVNXSXP8SmWvhYq5DFWqZZLjXkpE/iQhNEuy8JTWU4qeyhrniMWrJuUvn1ZNpw3BBLRiEWx3F+36HtqVCuqyDC2bRatWRSWbQTmVQjlfxNRcHGO2AMZno7jjXsMFs51GrX7kk8ZTcrH4bpuxVrNWZ8zAhj/AsmKS5ZMKy0sKa5TKbC2yxhQlxVIxgeWiAsuEY2xTkFirobEOaxrDjabe7bRycWHnP8baykuK0HerAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Alt text&quot;
        title=&quot;&quot;
        src=&quot;/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/f058b/participating_team.png&quot;
        srcset=&quot;/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/c26ae/participating_team.png 158w,
/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/6bdcf/participating_team.png 315w,
/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/f058b/participating_team.png 630w,
/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/40601/participating_team.png 945w,
/blog/static/87a3c9f3983cc93c2889ab268fc9d3c9/2bef9/participating_team.png 1024w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With only 17 hours to build a model and create a presentation for the first round, I knew sleep was off the table. The dataset, EEG data collected from rodents over two days, was massive—about 10GB! Handling such a large dataset was a first for me, and loading it on my local machine was a struggle. I decided to load the data in batches and perform exploratory data analysis (EDA) and preprocessing.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/51b19e7575e1addf6de66e43a23a14fc/01a87/data_eda.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 31.0126582278481%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABnUlEQVR42o2OT0hTAQDGHxtIO5rbMTBo4mxM3IuIFBXsIiymzkIYGBRKUEMSzGjO/xqikAiRzgkTKhtSCELQoWOgp/a2J+EjwW1odnhrDxFlbPv1fF069sHH7/Lx4xPefn7D/Oo64eUMK+/iRJdKLKzFWIlF+LK6y9LGJ159DBNdzus9I7KoEY3kmZ/bI/jsK5sbB2hHh6T2U6iqiuDtbMfuaKC58Qme20H8d9eoqWtCdIs8vjPCjZYOHG4X/q4YHd5FPK1zdLaFqbZ7uFBWyeDAazQtTyadIatmEURRRBAETCaTwf+t2Ww26PP5OE+xWDQo3KxvwGKxUXWliSp7M9fFbqy2SmzlVuprb3Hpcg0XK2xcq/PjutqGy+ml1tmu7xuxljsJPBo1RIVCgVKphBAI9tF1f4jh0HcGnm+yMAPdfSF6Hj5gfXabwORL7vX3Mjt1ysTwL6bHVGYmT3gxnmXo6U8+vM8ZQt3196GSUkgqe8hylsROhmT8mISiIO/KKFKarbhE8odMQsohxX/r1HTmkBPHSN800vsn/Js/uKkyYp+2L8kAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Alt text&quot;
        title=&quot;&quot;
        src=&quot;/blog/static/51b19e7575e1addf6de66e43a23a14fc/f058b/data_eda.png&quot;
        srcset=&quot;/blog/static/51b19e7575e1addf6de66e43a23a14fc/c26ae/data_eda.png 158w,
/blog/static/51b19e7575e1addf6de66e43a23a14fc/6bdcf/data_eda.png 315w,
/blog/static/51b19e7575e1addf6de66e43a23a14fc/f058b/data_eda.png 630w,
/blog/static/51b19e7575e1addf6de66e43a23a14fc/40601/data_eda.png 945w,
/blog/static/51b19e7575e1addf6de66e43a23a14fc/78612/data_eda.png 1260w,
/blog/static/51b19e7575e1addf6de66e43a23a14fc/01a87/data_eda.png 1288w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The data given to us was broadly classified into three stages of sleep:
Paradoxical sleep: REM stage with rapid eye movements and vivid dreaming; crucial for cognitive functions like memory consolidation.
Slow-wave sleep: Deep sleep stage characterized by slow delta waves; vital for physical restoration and recovery.
Wakefulness: Fully awake and alert; brain active, conscious of surroundings.&lt;/p&gt;
&lt;p&gt;Initial analysis revealed a class imbalance between paradoxical sleep and the other stages. A good classification model must handle all labels without bias, so I knew this was a problem to solve. Time for some feature engineering! Drawing on my physics background, I added features such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Power Spectral Density (PSD) &lt;/b&gt;​: EEG signals can be classified based on their frequency content. The frequncey components of these singals can be used to classifiy them into the following bands.
&lt;ul&gt;
&lt;li&gt;Delta (0.5-4 Hz): Delta waves are usually associated with deep sleep ​&lt;/li&gt;
&lt;li&gt;Theta (4-8 Hz): Theta waves are often observed during drowsiness or light sleep. ​&lt;/li&gt;
&lt;li&gt;Alpha (8-13 Hz): Alpha waves are prominent when an individual is awake but relaxed.​&lt;/li&gt;
&lt;li&gt;Beta (13-30 Hz): Beta waves are associated with active and alert mental activity.​&lt;/li&gt;
&lt;li&gt;Gamma (30-100 Hz and above): Gamma waves are associated with high-level cognitive processes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Maximum Minimum Distance (MMD)&lt;/b&gt;​: ​ TMeasures the distance between the maximum and minimum points (amplitude) in each epoch.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Hjorth parameters​&lt;/b&gt;​: Characterize the signal&apos;s activity, mobility, and complexity.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shannon entropy&lt;/b&gt;​​: Quantifies the information content or unpredictability of a signal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Next, I experimented with different models. With labeled data, it was a typical supervised learning problem. The challenge was whether to use the entire dataset, which would increase training time, or sample from it for initial comparisons. With only 12 hours left, I opted to sample 30% of the data to test models like LSTM, Random Forest, and Gradient Boosting (XGBoost, LightGBM). The LSTM and XGBoost models performed best. To address class imbalance, I used methods like SMOTE and balanced sampling. After training on the entire dataset (~70%), XGBoost outperformed LSTM in both accuracy and F1 score. With just 4 hours left, I focused on creating our presentation deck. You can check it out &lt;a href=&quot;https://docs.google.com/presentation/d/1MbHzhTogJosec2Jt0jlLzf8lzIGcn9WX/edit?usp=sharing&amp;#x26;ouid=111199971333324653064&amp;#x26;rtpof=true&amp;#x26;sd=true&quot;&gt;here&lt;/a&gt;. Confident in our results, I continued refining the model instead of sleeping. We made it to the finals!&lt;/p&gt;
&lt;p&gt;For the final round, I added more features, fine-tuned hyperparameters, and created an ensemble of the top models. We also had to measure our models&apos; reliability, a challenge in itself. Without any sleep, I updated our final deck and model iterations just an hour before the deadline. The last 34 hours were the most productive of my life, no doubt. When the results were announced, my anxiety turned into relief and excitement as we were declared &lt;a href=&quot;https://bigdata.sc.edu/5th-national-bdhs-case-competition/&quot;&gt;winners&lt;/a&gt;. We won $5k, which was pretty cool too. This hackathon was an incredible journey, from almost not participating to winning. It was quite an adventure!&lt;/p&gt;</content:encoded></item></channel></rss>